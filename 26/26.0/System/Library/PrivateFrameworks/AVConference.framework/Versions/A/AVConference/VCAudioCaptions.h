@class NSUUID, NSString, VCCaptionTaskInfo, ASBDWrapper, NSSet, VCCaptionsConfig, NSLocale, NSObject, NSMutableArray, AVAudioFormat, NSNumber;
@protocol OS_dispatch_queue, VCAudioCaptionsDelegate, OS_dispatch_semaphore;

@interface VCAudioCaptions : VCObject <SFSpeechAnalyzerLanguageDetectorResultDelegate, VCAudioCaptionsProtocol, VCAudioIOSink> {
    BOOL _isEnabled;
    BOOL _isPrewarmed;
    BOOL _isStarted;
    BOOL _isLocal;
    BOOL _useSpeechAnalyzerV2API;
    BOOL _enableSpeechDetector;
    unsigned int _lastVoiceAcitivty;
    int _recognizerState;
    VCCaptionTaskInfo *_currentTaskInfo;
    NSObject<OS_dispatch_queue> *_captionsQueue;
    NSObject<OS_dispatch_queue> *_delegateQueue;
    struct __CFAllocator { } *_copyBufferAllocator;
    struct __CFAllocator { } *_audioBufferAllocator;
    struct __CFAllocator { } *_pcmCopyBufferAllocator;
    AVAudioFormat *_frameworkAudioFormat;
    struct __CFAllocator { } *_avAudioPCMAudioBufferAllocator;
    long long _currentTime;
    int _timescale;
    long long _epoch;
    VCCaptionsConfig *_config;
    NSLocale *_locale;
    NSLocale *_sourceLocale;
    unsigned char _taskHint;
    BOOL _explicitLanguageFilterEnabled;
    unsigned char _callType;
    id<VCAudioCaptionsDelegate> _delegate;
    unsigned long long _captioningRequestCount;
    BOOL _formatForNewLinesEnabled;
    struct opaqueRTCReporting { } *_reportingAgent;
    double _captionsEnabledDuration;
    double _lastCaptionsEnabledTime;
    struct { long long value; int timescale; unsigned int flags; long long epoch; } _lastAudioProcessedTime;
    double _captionedAudioDuration;
    unsigned int _captionTaskCount;
    double _captionsLastUtteranceStart;
    double _captionsUtteranceDuration;
    double _translatedLatencyAverage;
    void *_previousConverterSamples;
    struct __CFAllocator { } *_previousConverterSamplesAllocator;
    struct OpaqueAudioConverter { } *_audioConverter;
    BOOL _isAudioConverterActive;
    ASBDWrapper *_captionsFormat;
    ASBDWrapper *_inputFormat;
    unsigned int _currentUtteranceNumber;
    unsigned int _translatedUtteranceNumber;
    NSObject<OS_dispatch_semaphore> *_teardownSemaphore;
    BOOL _inputFormatDidChange;
    NSMutableArray *_captionTasks;
    void *_logCaptionsDump;
    BOOL _isCaptionsDebugDumpEnabled;
    unsigned int _logMessageCounter;
    NSString *_detectedLanguageCode;
}

@property (readonly, nonatomic) unsigned char frameworkType;
@property (nonatomic) id<VCAudioCaptionsDelegate> delegate;
@property (copy, nonatomic) NSLocale *locale;
@property (copy, nonatomic) NSLocale *sourceLocale;
@property (readonly, nonatomic) BOOL enabled;
@property (retain, nonatomic) NSSet *localLanguages;
@property (retain, nonatomic) NSSet *remoteLanguages;
@property (nonatomic) BOOL remoteCanDisplay;
@property (retain, nonatomic) NSString *taskIdentifier;
@property (nonatomic) unsigned char taskHint;
@property (nonatomic) BOOL enableV2SpeechAPI;
@property (nonatomic) BOOL languageDetectorEnabled;
@property (retain, nonatomic) NSNumber *languageDetectorReportingFrequency;
@property (nonatomic) unsigned char translatorMode;
@property (copy, nonatomic) NSUUID *translatorIdentifier;
@property (nonatomic) long long streamToken;
@property (nonatomic, getter=isExplicitLanguageFilterEnabled) BOOL explicitLanguageFilterEnabled;
@property (nonatomic) unsigned char callType;
@property (nonatomic, getter=isFormatForNewLinesEnabled) BOOL formatForNewLinesEnabled;
@property (readonly) unsigned long long hash;
@property (readonly) Class superclass;
@property (readonly, copy) NSString *description;
@property (readonly, copy) NSString *debugDescription;

+ (BOOL)captionsSupportedWithErrorCode:(long long *)a0;
+ (BOOL)captionsSupported;
+ (BOOL)isTaskHintSupported:(unsigned char)a0 withReturnCode:(long long *)a1;
+ (BOOL)shouldAllocateNewAllocator:(void *)a0 streamDesc:(const struct AudioStreamBasicDescription { double x0; unsigned int x1; unsigned int x2; unsigned int x3; unsigned int x4; unsigned int x5; unsigned int x6; unsigned int x7; unsigned int x8; } *)a1 referenceStreamDesc:(const struct AudioStreamBasicDescription { double x0; unsigned int x1; unsigned int x2; unsigned int x3; unsigned int x4; unsigned int x5; unsigned int x6; unsigned int x7; unsigned int x8; } *)a2;
+ (long long)speechRecognitionTaskHintFromCaptionsTaskHint:(unsigned char)a0;

- (void)dealloc;
- (void)stop;
- (id)taskInfoForTask:(id)a0;
- (void)updateConfig:(id)a0;
- (void)stopWithCompletionHandler:(id /* block */)a0;
- (void)enableCaptions:(BOOL)a0;
- (void)destroyCaptions;
- (void)prewarmCaptions;
- (void)updateCaptionsUtteranceDuration;
- (void)applyOnIdleWithBlock:(id /* block */)a0;
- (void)callCompletionHandler:(id /* block */)a0 withResult:(BOOL)a1;
- (BOOL)captionsDebugDumpEnabled;
- (struct opaqueCMSampleBuffer { } *)convertSamples:(char *)a0 numSamples:(int)a1;
- (BOOL)createAudioConverterWithInputFormat:(const struct AudioStreamBasicDescription { double x0; unsigned int x1; unsigned int x2; unsigned int x3; unsigned int x4; unsigned int x5; unsigned int x6; unsigned int x7; unsigned int x8; } *)a0 outputFormat:(const struct AudioStreamBasicDescription { double x0; unsigned int x1; unsigned int x2; unsigned int x3; unsigned int x4; unsigned int x5; unsigned int x6; unsigned int x7; unsigned int x8; } *)a1 converter:(struct OpaqueAudioConverter **)a2;
- (struct opaqueCMSampleBuffer { } *)createSampleBufferWithFormat:(const struct AudioStreamBasicDescription { double x0; unsigned int x1; unsigned int x2; unsigned int x3; unsigned int x4; unsigned int x5; unsigned int x6; unsigned int x7; unsigned int x8; } *)a0 samples:(char *)a1 numSamples:(int)a2;
- (void)dispatchedSetCallType:(unsigned char)a0;
- (void)dispatchedSetExplicitLanguageFilterEnabled:(BOOL)a0;
- (void)dispatchedSetFormatForNewLinesEnabled:(BOOL)a0;
- (void)dispatchedSetLanguageDetectorEnabled:(BOOL)a0;
- (void)dispatchedSetLanguageDetectorReportingFrequency:(id)a0;
- (void)dispatchedSetLocale:(id)a0;
- (void)dispatchedSetTaskHint:(unsigned char)a0;
- (void)dumpCaptionsIfNeededForCaptionsTranscription:(id)a0;
- (BOOL)enableLanguageDetector:(BOOL)a0;
- (void)finishCaptions;
- (void)gatherRealtimeStats:(struct __CFDictionary { } *)a0;
- (BOOL)handleStateLoadedError:(id *)a0;
- (void)handleStateStopping;
- (BOOL)idleStateToState:(int)a0 withReason:(unsigned char)a1 error:(id *)a2;
- (id)initWithDelegate:(id)a0 isLocal:(BOOL)a1 taskIdentifier:(id)a2 reportingAgent:(struct opaqueRTCReporting { } *)a3;
- (id)initWithSpeechConfig:(const struct tagVCAudioCaptionsSpeechConfig { id x0; id x1; struct opaqueRTCReporting *x2; BOOL x3; } *)a0;
- (BOOL)isTaskHintSetWithReturnCode:(long long *)a0;
- (void)loadSpeechAssets;
- (BOOL)loadedStateToState:(int)a0 withReason:(unsigned char)a1 error:(id *)a2;
- (id)newPCMSampleBufferWithSamples:(char *)a0 numSamples:(int)a1 pcmFormat:(id)a2;
- (void)pushAudioSamples:(struct opaqueVCAudioBufferList { } *)a0;
- (void)pushSamples:(char *)a0 numSamples:(int)a1 hostTime:(double)a2;
- (BOOL)reallocCopyBufferAllocatorWithFormat:(const struct AudioStreamBasicDescription { double x0; unsigned int x1; unsigned int x2; unsigned int x3; unsigned int x4; unsigned int x5; unsigned int x6; unsigned int x7; unsigned int x8; } *)a0;
- (void)recordAudioSampleMetrics;
- (void)reportSourceLocale;
- (BOOL)runningStateToState:(int)a0 withReason:(unsigned char)a1 error:(id *)a2;
- (void)sendTranscriptionResult:(id)a0 taskInfo:(id)a1;
- (BOOL)setUpCaptionsWithError:(id *)a0;
- (BOOL)shouldEnableCaptions;
- (BOOL)shouldPushSamples;
- (BOOL)shouldSetLocale:(id)a0 withError:(id *)a1;
- (BOOL)shouldSetTaskHint:(unsigned char)a0 withError:(id *)a1;
- (void)speechAnalyzer:(id)a0 didProduceLanguageHypothesis:(id)a1;
- (void)speechAnalyzer:(id)a0 didStopLanguageDetectorWithError:(id)a1;
- (void)start:(const struct AudioStreamBasicDescription { double x0; unsigned int x1; unsigned int x2; unsigned int x3; unsigned int x4; unsigned int x5; unsigned int x6; unsigned int x7; unsigned int x8; } *)a0 forToken:(long long)a1 withCompletionHandler:(id /* block */)a2;
- (BOOL)startCaptionsWithError:(id *)a0;
- (void)stopCaptions;
- (BOOL)stoppingStateToState:(int)a0 withReason:(unsigned char)a1 error:(id *)a2;
- (BOOL)transitionToState:(int)a0 withReason:(unsigned char)a1 error:(id *)a2;
- (BOOL)updateAudioConverterForStreamDescription:(const struct AudioStreamBasicDescription { double x0; unsigned int x1; unsigned int x2; unsigned int x3; unsigned int x4; unsigned int x5; unsigned int x6; unsigned int x7; unsigned int x8; } *)a0;

@end
