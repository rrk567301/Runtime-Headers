@class NSUUID, NSString, NSLocale, VCCaptionsGibberishDetector, VCAudioCaptionsBufferInfoCollection, VCMediaAnalyzer, VCAudioCaptions, NSObject;
@protocol VCMediaAnalyzerSourceDelegate, OS_dispatch_semaphore, OS_dispatch_queue, VCCaptionsSourceDelegate;

@interface VCAudioMachineLearningCoordinator : VCObject <VCAudioCaptionsDelegate, VCMediaAnalyzerDelegate, VCCaptionsSource, VCMediaAnalyzerSource> {
    id<VCCaptionsSourceDelegate> _captionsDelegate;
    NSObject<OS_dispatch_queue> *_delegateQueue;
    VCCaptionsGibberishDetector *_gibberishDetector;
    int _reportingModuleID;
    unsigned char _configCallSource;
    unsigned char _configUsage;
    BOOL _isOwnerOfReportingAgent;
    long long _initialStreamToken;
    long long _currentMediaAnalyzerStreamToken;
    struct os_unfair_lock_s { unsigned int _os_unfair_lock_opaque; } _stateLock;
    BOOL _invalidated;
    NSObject<OS_dispatch_semaphore> *_startStopSemaphore;
    VCAudioCaptionsBufferInfoCollection *_bufferInfos;
    BOOL _oneToOneEnabled;
    struct tagVCAudioMachineLearningCoordinatorVoiceDetectorInfo { struct opaqueVCVoiceDetector *voiceDetector; BOOL isVoiceDetectorRunning; struct tagVCAudioFrameFormat { struct AudioStreamBasicDescription { double mSampleRate; unsigned int mFormatID; unsigned int mFormatFlags; unsigned int mBytesPerPacket; unsigned int mFramesPerPacket; unsigned int mBytesPerFrame; unsigned int mChannelsPerFrame; unsigned int mBitsPerChannel; unsigned int mReserved; } format; unsigned int samplesPerFrame; } lastUsedAudioFormat; } _voiceDetectorInfo;
    BOOL _forceCaptionsVoiceDetection;
    VCMediaAnalyzer *_mediaAnalyzer;
    id<VCMediaAnalyzerSourceDelegate> _mediaAnalyzerSourceDelegate;
    long long _mediaAnalyzerAnalysisType;
    id _delegate;
    BOOL _delegateAudioStackStarted;
    struct __CFAllocator { } *_audioSampleBufferAllocator;
    BOOL _isReadyForCaptioning;
    BOOL _isLocal;
    NSString *_taskIdentifier;
    BOOL _isV2SpeechAPIEnabled;
    NSLocale *_sourceLocale;
    NSLocale *_locale;
    VCAudioCaptions *_audioCaptions;
    unsigned char _translatorMode;
    unsigned char _captionsFrameworkType;
    NSUUID *_translatorIdentifier;
    NSUUID *_reportingSamplingUUID;
    int _direction;
    struct opaqueCMSimpleQueue { } *_audioProcessingEventQueue;
    unsigned int _activeModuleIDs;
    unsigned int _moduleIDsEnabled;
}

@property (nonatomic) long long currentlyCaptionedStreamToken;
@property (nonatomic) long long captionsState;
@property (nonatomic) double lowPriorityThresholdSeconds;
@property (readonly, nonatomic) BOOL captionsSupported;
@property (readonly, nonatomic) BOOL captionsEnabled;
@property (readonly) unsigned long long hash;
@property (readonly) Class superclass;
@property (readonly, copy) NSString *description;
@property (readonly, copy) NSString *debugDescription;

+ (id)errorCodeWithEvent:(unsigned int)a0 errorPath:(id)a1;

- (void)dealloc;
- (void)invalidate;
- (struct os_unfair_lock_s { unsigned int x0; } *)stateLock;
- (void)enableCaptions:(BOOL)a0;
- (void)setOneToOneModeEnabled:(BOOL)a0;
- (id)initWithConfiguration:(const struct tagVCAudioMachineLearningCoordinatorConfiguration { BOOL x0; BOOL x1; id x2; struct opaqueRTCReporting *x3; unsigned char x4; unsigned char x5; long long x6; id x7; id x8; int x9; } *)a0 delegate:(id)a1;
- (void)captions:(id)a0 didChangeSourceLocale:(id)a1;
- (BOOL)lockedEnableCaptions:(BOOL)a0 withError:(id *)a1;
- (BOOL)setUpInternalStateForReporting:(unsigned char)a0;
- (void)captions:(id)a0 didProduceLanguageHypothesis:(id)a1 streamToken:(long long)a2;
- (void)captions:(id)a0 didStopLanguageDetectorWithError:(id)a1 streamToken:(long long)a2;
- (id)captionsDelegate;
- (struct __CFDictionary { } *)clientSpecificUserInfo;
- (void)didConfigureCaptionsWithError:(id)a0;
- (void)didDisableCaptions:(BOOL)a0 error:(id)a1;
- (void)didEnableCaptions:(BOOL)a0 error:(id)a1;
- (void)didStartCaptioningWithReason:(unsigned char)a0 streamToken:(long long)a1;
- (void)didStopCaptioningWithReason:(unsigned char)a0 streamToken:(long long)a1;
- (void)didUpdateCaptions:(id)a0;
- (void)disableMediaAnalyzerAndNotifyClient;
- (void)enableMediaAnalyzer:(BOOL)a0;
- (void)enableV2SpeechAPI:(BOOL)a0;
- (id)initWithOneToOneEnabled:(BOOL)a0 isLocal:(BOOL)a1 taskIdentifier:(id)a2 reportingAgent:(struct opaqueRTCReporting { } *)a3 delegate:(id)a4;
- (BOOL)lockedCaptionsEnabled;
- (id)lockedDelegate;
- (BOOL)lockedEnableMediaAnalyzer:(BOOL)a0 withError:(id *)a1;
- (void)lockedRegisterMediaAnalyzerWithStreamToken:(long long)a0;
- (void)mediaAnalyzer:(id)a0 didProduceMediaAnalysis:(id)a1 streamToken:(long long)a2;
- (id)mediaAnalyzerSourceDelegate;
- (BOOL)prewarmCaptionsWithError:(id *)a0;
- (void)processAudioControlEventEnable:(BOOL)a0 moduleID:(unsigned int)a1;
- (void)registerCaptionsEventDelegate:(id)a0;
- (void)registerMediaAnalyzerSourceDelegate:(id)a0;
- (BOOL)registerStreamWithConfig:(const struct tagVCAudioCaptionsStreamConfig { long long x0; struct AudioStreamBasicDescription { double x0; unsigned int x1; unsigned int x2; unsigned int x3; unsigned int x4; unsigned int x5; unsigned int x6; unsigned int x7; unsigned int x8; } x1; } *)a0;
- (void)removeDelegateAudioStackIfNeeded;
- (void)reportCaptionsUsage:(unsigned char)a0;
- (struct __CFDictionary { } *)reportingInitialConfiguration;
- (void)setCaptionsSourceLocale:(id)a0;
- (void)setMediaAnalyzerTaskType:(long long)a0;
- (BOOL)setUpAudioCaptionsUsingFrameworkType:(unsigned char)a0;
- (void)setUpForTranslatorMode:(unsigned char)a0;
- (BOOL)setUpReportingAgent;
- (BOOL)startDelegateAudioStackIfNeededWithError:(id *)a0;
- (BOOL)toggleDelegateAudioStackEnabledIfNeeded:(BOOL)a0 withError:(id *)a1;
- (void)unregisterStreamTokens;
- (void)updateCaptionsConfig:(id)a0;

@end
