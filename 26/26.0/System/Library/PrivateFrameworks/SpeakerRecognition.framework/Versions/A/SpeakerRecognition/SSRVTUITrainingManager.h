@class CSAsset, SSRVTUITrainingServiceClient, AVAudioPlayer, NSMutableDictionary, NSObject, NSMutableArray, CSAudioZeroCounter, CSVTUIKeywordDetector, NSString, SFSpeechRecognizer, SSRVoiceProfile, CSVTUIEndpointAnalyzer, CSPlainAudioFileWriter, SecureAsset, CSVTUITrainingSession, CSDispatchGroup, NSUUID;
@protocol CSVTUIAudioSession, CSAudioProviderSelecting, OS_dispatch_queue, SSRVTUITrainingManagerDelegate;

@interface SSRVTUITrainingManager : NSObject <CSVTUITrainingSessionDelegate, CSVTUIAudioSessionDelegate, CSVTUIEndpointAnalyzerDelegate, SSRVTUITrainingServiceDelegate, SSRVTUITrainingService> {
    BOOL _performRMS;
    NSString *_locale;
    NSString *_vtAssetConfigVersion;
    id<CSVTUIAudioSession> _audioSession;
    CSVTUIEndpointAnalyzer *_audioAnalyzer;
    CSVTUIKeywordDetector *_keywordDetector;
    NSMutableArray *_trainingSessions;
    CSVTUITrainingSession *_currentTrainingSession;
    long long _sessionNumber;
    BOOL _suspendAudio;
    NSObject<OS_dispatch_queue> *_queue;
    id /* block */ _cleanupCompletion;
    SFSpeechRecognizer *_speechRecognizer;
    CSAsset *_currentAsset;
    SecureAsset *_currentSecureAsset;
    SSRVoiceProfile *_profile;
    CSDispatchGroup *_didStopWaitingGroup;
    NSUUID *_mhUUID;
    CSAudioZeroCounter *_audioZeroCounter;
    BOOL _shouldTrainViaXPC;
    SSRVTUITrainingServiceClient *_trainingServiceClient;
    AVAudioPlayer *_audioPlayer;
    NSMutableDictionary *_pageAttemptMap;
    long long _lastAttemptedUtterance;
    id<CSAudioProviderSelecting> _audioProviderSelector;
    unsigned long long _audioStartRecordingHostTime;
    BOOL _shouldUseRecordingStartHostTime;
}

@property (retain, nonatomic) CSPlainAudioFileWriter *audioFileWriter;
@property (readonly) SSRVoiceProfile *voiceProfile;
@property float rms;
@property (weak, nonatomic) id<SSRVTUITrainingManagerDelegate> delegate;
@property (readonly) BOOL speechRecognizerAvailable;
@property (readonly) unsigned long long audioSource;
@property BOOL suspendAudio;
@property (readonly) unsigned long long hash;
@property (readonly) Class superclass;
@property (readonly, copy) NSString *description;
@property (readonly, copy) NSString *debugDescription;

+ (id)trainingManagerWithLocaleID:(id)a0 withAppDomain:(id)a1 withSiriSharedUserId:(id)a2;
+ (id)sharedtrainingSessionQueue;
+ (id)trainingManagerWithLocaleID:(id)a0 withAppDomain:(id)a1;

- (void)reset;
- (void)setLocaleIdentifier:(id)a0;
- (void).cxx_destruct;
- (void)prepareWithCompletion:(id /* block */)a0;
- (BOOL)_stopAudioSession;
- (void)CSVTUITrainingSessionStopListen;
- (BOOL)CSVTUITrainingSession:(id)a0 hasTrainUtterance:(id)a1 languageCode:(id)a2 payload:(BOOL)a3;
- (void)stopRMS;
- (void)CSVTUIRemoteTrainingSessionRMSAvailable:(float)a0;
- (void)CSVTUITrainingSessionRMSAvailable:(float)a0;
- (unsigned long long)_audioSource;
- (void)_beginOfSpeechDetected;
- (BOOL)_createAudioAnalyzer;
- (void)_createAudioSessionRecorderWithAudioProviderSelector:(id)a0;
- (void)_destroyAudioSession;
- (void)_endOfSpeechDetected;
- (void)_fetchCurrentAsset;
- (id)_fetchPreInstalledSecureAsset;
- (id)_getAudioToneFileName:(int)a0;
- (void)_logSessionSummary;
- (BOOL)_otaAssetsAvailable;
- (void)_playSoundsEffect:(int)a0;
- (void)_resetAudioAnalyzer;
- (id)_secureAssetWithAssetResourcePathURL:(id)a0 assetFileName:(id)a1;
- (BOOL)_setupAudioSession;
- (BOOL)_shouldShowHeadsetDisconnectionMessage;
- (BOOL)_startAudioSession;
- (void)_updateAttemptForPageNumber:(unsigned long long)a0;
- (unsigned long long)_validateRecordingStartHostTime:(unsigned long long)a0;
- (void)audioSessionDidStartRecording:(BOOL)a0 error:(id)a1;
- (void)audioSessionDidStopRecording:(long long)a0;
- (void)audioSessionErrorDidOccur:(id)a0;
- (void)audioSessionRecordBufferAvailable:(id)a0;
- (void)audioSessionUnsupportedAudioRoute;
- (BOOL)cancelTrainingForID:(long long)a0;
- (id)cleanupWithCompletion:(id /* block */)a0;
- (void)closeSessionBeforeStartWithStatus:(int)a0 successfully:(BOOL)a1 completionWithResult:(id /* block */)a2;
- (void)closeSessionBeforeStartWithStatus:(int)a0 successfully:(BOOL)a1 withCompletion:(id /* block */)a2;
- (BOOL)createKeywordDetector;
- (void)createSpeechRecognizer;
- (void)destroySpeakerTrainer;
- (void)didDetectForceEndPoint;
- (void)endpointer:(id)a0 didDetectHardEndpointAtTime:(double)a1;
- (void)endpointer:(id)a0 didDetectStartpointAtTime:(double)a1;
- (void)getAudioSessionID:(id /* block */)a0;
- (id)initWithLocaleIdentifier:(id)a0 withAppDomain:(id)a1;
- (id)initWithLocaleIdentifier:(id)a0 withAppDomain:(id)a1 withSiriSharedUserId:(id)a2 withAudioProviderSelector:(id)a3 shouldTrainViaXPC:(BOOL)a4;
- (void)playSoundEffectWithAudioTone:(int)a0;
- (void)playSoundsEffect:(long long)a0;
- (void)setRecordingStartHostTime:(unsigned long long)a0;
- (BOOL)shouldPerformRMS;
- (void)startRMS;
- (long long)trainUtterance:(long long)a0 shouldUseASR:(BOOL)a1 completion:(id /* block */)a2;
- (long long)trainUtterance:(long long)a0 shouldUseASR:(BOOL)a1 mhUUID:(id)a2 completionWithResult:(id /* block */)a3;
- (id)updateTrainingManagerForDevice:(unsigned long long)a0 trainingDeviceUUIDList:(id)a1;
- (void)updateVoiceProfile:(id)a0;

@end
