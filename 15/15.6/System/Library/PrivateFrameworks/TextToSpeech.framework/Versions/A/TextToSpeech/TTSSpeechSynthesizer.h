@class NSMutableArray, NSString, NSArray, NSDictionary, NSMutableDictionary, NSObject, _TtC12TextToSpeech15CoreSynthesizer;
@protocol OS_voucher, TTSSpeechSynthesizerDelegate, OS_dispatch_queue;

@interface TTSSpeechSynthesizer : NSObject <TTSSpeechRequestDelegate> {
    long long _footprint;
    id<TTSSpeechSynthesizerDelegate> _delegate;
    char _useSharedSession;
    char _audioSessionIDIsValid;
    unsigned int _audioSessionID;
    unsigned int _audioDeviceId;
    unsigned int _audioQueueFlags;
    NSMutableDictionary *_channels;
    NSObject<OS_dispatch_queue> *_queue;
    NSMutableArray *_speechRequests;
    struct { unsigned char delegateStartWithRequest : 1; unsigned char delegateFinishWithRequest : 1; unsigned char delegateFinishWithPhonemesSpokenWithRequest : 1; unsigned char delegatePauseWithRequest : 1; unsigned char delegateContinueWithRequest : 1; unsigned char delegateWillSpeakWithRequest : 1; unsigned char delegateDidEncounterMarkerWithRequest : 1; unsigned char willUseInput : 1; } _synthesizerFlags;
    unsigned long long _synthesizerInstanceID;
    NSArray *_outputChannels;
    NSMutableDictionary *_testingLastRuleConversion;
}

@property (retain, nonatomic) NSObject<OS_voucher> *voucher;
@property (retain, nonatomic) _TtC12TextToSpeech15CoreSynthesizer *coreSynth;
@property (weak, nonatomic) id<TTSSpeechSynthesizerDelegate> delegate;
@property (retain, nonatomic) NSString *speechSource;
@property (retain, nonatomic) NSObject<OS_dispatch_queue> *delegateTargetQueue;
@property (nonatomic) float rate;
@property (nonatomic) float pitch;
@property (nonatomic) float volume;
@property (nonatomic) unsigned int audioDeviceId;
@property (retain, nonatomic) NSArray *audioEffects;
@property (retain, nonatomic) NSString *voiceIdentifier;
@property (retain, nonatomic) NSString *bundleIdentifier;
@property (readonly, nonatomic) NSString *resolvedVoiceIdentifier;
@property (nonatomic) unsigned long long requestClientIdentifier;
@property (nonatomic) void *speakingRequestClientContext;
@property (nonatomic) char supportsAccurateWordCallbacks;
@property (nonatomic) char skipLuthorRules;
@property (nonatomic) unsigned int audioQueueFlags;
@property (copy, nonatomic) NSArray *userSubstitutions;
@property (copy, nonatomic) NSArray *phonemeSubstitutions;
@property (copy, nonatomic) id /* block */ audioBufferCallback;
@property (retain, nonatomic) NSDictionary *perVoiceSettings;
@property (retain, nonatomic) NSArray *outputChannels;
@property (nonatomic) char ignoreSubstitutions;
@property (nonatomic) char synthesizeSilently;
@property (readonly) unsigned long long hash;
@property (readonly) Class superclass;
@property (readonly, copy) NSString *description;
@property (readonly, copy) NSString *debugDescription;

+ (void)initialize;
+ (id)combinedProsodyMarkupForIdentifier:(id)a0 string:(id)a1 rate:(id)a2 pitch:(id)a3 volume:(id)a4;
+ (id)genericMarkMarkupForIdentifier:(id)a0 name:(id)a1;
+ (id)speechMarkupStringForType:(long long)a0 forIdentifier:(id)a1 string:(id)a2;
+ (id)voiceAccessQueue;
+ (id)voiceForIdentifier:(id)a0;
+ (void)_initializeServers;
+ (id)_speechVoiceForIdentifier:(id)a0 language:(id)a1 footprint:(long long)a2;
+ (id)audioFileSettingsForVoice:(id)a0;
+ (id)availableLanguageCodes;
+ (char)employSpeechMarkupForType:(long long)a0 identifier:(id)a1 withLanguage:(id)a2;
+ (char)isSystemVoice:(id)a0;
+ (id)remapVoiceIdentifier:(id)a0;
+ (void)setVoiceAssetsForTesting:(id)a0;
+ (id)supportedIPAPhonemeLanguages;
+ (id)synthesizerForSynthesizerID:(unsigned long long)a0;
+ (void)testingSetAllVoices:(id)a0;
+ (id)unavailableVoiceIdentifiers;
+ (id)voiceAssetsForTesting;

- (void)dealloc;
- (id)init;
- (void).cxx_destruct;
- (void)_setDelegate:(id)a0;
- (id)delegate;
- (void)setDelegate:(id)a0;
- (char)isSpeaking;
- (char)continueSpeakingRequest:(id)a0 withError:(id *)a1;
- (long long)footprint;
- (char)pauseSpeakingRequest:(id)a0 atNextBoundary:(long long)a1 error:(id *)a2;
- (char)startSpeakingString:(id)a0 withLanguageCode:(id)a1 request:(id *)a2 error:(id *)a3;
- (char)stopSpeakingAtNextBoundary:(long long)a0 synchronously:(char)a1 error:(id *)a2;
- (char)stopSpeakingRequest:(id)a0 atNextBoundary:(long long)a1 error:(id *)a2;
- (void)setFootprint:(long long)a0;
- (id)speechString;
- (char)startSpeakingSSML:(id)a0 withLanguageCode:(id)a1 jobIdentifier:(id)a2 request:(id *)a3 error:(id *)a4;
- (void)_processUserSubstitutionsToText:(id)a0 request:(id)a1 bundleIdentifier:(id)a2 voice:(id)a3;
- (char)_continueSpeakingRequest:(id)a0 withError:(id *)a1;
- (id)_determineSubstitution:(id)a0 speechString:(id)a1 wordRange:(struct _NSRange { unsigned long long x0; unsigned long long x1; })a2 request:(id)a3;
- (id)_makeRequestForVoice:(id)a0 andLanguageCode:(id)a1;
- (void)_mediaServicesDied;
- (char)_pauseSpeakingRequest:(id)a0 atNextBoundary:(long long)a1 synchronously:(char)a2 error:(id *)a3;
- (id)_preprocessText:(id)a0 languageCode:(id)a1;
- (id)_processMarker:(id)a0 forRequest:(id)a1;
- (id)_resolveVoiceForLanguage:(id)a0;
- (char)_skipSubstition:(id)a0 language:(id)a1 bundleIdentifier:(id)a2 voice:(id)a3;
- (char)_startSpeakingString:(id)a0 orSSMLString:(id)a1 withLanguageCode:(id)a2 jobId:(id)a3 request:(id *)a4 error:(id *)a5;
- (char)_stopSpeakingRequest:(id)a0 atNextBoundary:(long long)a1 synchronously:(char)a2 error:(id *)a3;
- (char)_substitutionLanguageMatchesSpecialCase:(id)a0 withLanguage:(id)a1;
- (char)continueSpeakingWithError:(id *)a0;
- (id)getPerVoiceSettings;
- (float)maximumRate;
- (float)minimumRate;
- (char)pauseSpeakingAtNextBoundary:(long long)a0 error:(id *)a1;
- (char)pauseSpeakingAtNextBoundary:(long long)a0 synchronously:(char)a1 error:(id *)a2;
- (char)pauseSpeakingRequest:(id)a0 atNextBoundary:(long long)a1 synchronously:(char)a2 error:(id *)a3;
- (id)resolvedVoiceIdentifierForLanguageCode:(id)a0;
- (oneway void)speechRequest:(id)a0 didStopWithSuccess:(char)a1 phonemesSpoken:(id)a2 forService:(id)a3 error:(id)a4;
- (oneway void)speechRequest:(id)a0 withMarker:(id)a1 didStartForService:(id)a2;
- (oneway void)speechRequestDidContinue:(id)a0 forService:(id)a1;
- (oneway void)speechRequestDidPause:(id)a0 forService:(id)a1;
- (oneway void)speechRequestDidStart:(id)a0 forService:(id)a1;
- (char)startSpeakingSSML:(id)a0 withLanguageCode:(id)a1 request:(id *)a2 error:(id *)a3;
- (char)startSpeakingString:(id)a0 error:(id *)a1;
- (char)startSpeakingString:(id)a0 request:(id *)a1 error:(id *)a2;
- (char)startSpeakingString:(id)a0 toURL:(id)a1 withLanguageCode:(id)a2 error:(id *)a3;
- (char)startSpeakingString:(id)a0 toURL:(id)a1 withLanguageCode:(id)a2 request:(id *)a3 error:(id *)a4;
- (char)startSpeakingString:(id)a0 withLanguageCode:(id)a1 error:(id *)a2;
- (char)startSpeakingString:(id)a0 withLanguageCode:(id)a1 jobIdentifier:(id)a2 request:(id *)a3 error:(id *)a4;
- (char)stopSpeakingAtNextBoundary:(long long)a0 error:(id *)a1;
- (char)stopSpeakingRequest:(id)a0 atNextBoundary:(long long)a1 synchronously:(char)a2 error:(id *)a3;
- (unsigned long long)synthesizerInstanceID;
- (id)testingLastRuleConversion;
- (void)testingSetLastRuleConversion:(id)a0 replacement:(id)a1;
- (void)useSpecificAudioSession:(unsigned int)a0;
- (id)voiceResolver;

@end
