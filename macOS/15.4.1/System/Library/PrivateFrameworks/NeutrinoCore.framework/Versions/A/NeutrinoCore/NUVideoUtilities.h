@class NSArray;

@interface NUVideoUtilities : NSObject

@property (class, readonly, nonatomic) NSArray *preferredSourcePixelFormats;
@property (class, readonly, nonatomic) NSArray *preferedDestinationPixelFormats;
@property (class, readonly, nonatomic) NSArray *preferedDestinationPixelFormatsForHDR;

+ (float)nominalFrameRateForAsset:(id)a0 error:(out id *)a1;
+ (id)_preferedPixelFormatsForUsage:(long long)a0;
+ (BOOL)asset:(id)a0 containsDuplicatePTSSamples:(BOOL *)a1 assetTrack:(id)a2 error:(out id *)a3;
+ (BOOL)assetIsCinematicAudio:(id)a0;
+ (id)assetReaderAudioSettingsForTrackType:(BOOL)a0;
+ (id)assetWriterAudioSettingsForAudioTrackFormatDescription:(struct opaqueCMFormatDescription { } *)a0;
+ (id)assetWriterAudioSettingsForTrackWithSampleRate:(double)a0 isAmbisonic:(BOOL)a1;
+ (BOOL)audioTrackIsCinematicAudio:(id)a0;
+ (id)auxiliaryTrackInAsset:(id)a0 ofType:(long long)a1 error:(out id *)a2;
+ (id)bestOutputSettingsPresetForTargetVideoSize:(struct { long long x0; long long x1; })a0 codec:(unsigned int)a1;
+ (id)cinematicAudioTrackInAsset:(id)a0;
+ (struct { struct { long long x0; long long x1; } x0; struct { long long x0; long long x1; } x1; })cleanApertureOfTrack:(id)a0 oriented:(BOOL)a1;
+ (id)cleanApertureVideoSettingsFor:(struct { struct { long long x0; long long x1; } x0; struct { long long x0; long long x1; } x1; })a0 scale:(struct { long long x0; long long x1; })a1 videoSize:(struct { long long x0; long long x1; })a2;
+ (id)compositionFromVideoComposition:(id)a0;
+ (BOOL)compositionInstructions:(id)a0 areEqualToCompositionInstructions:(id)a1;
+ (id)computeMalformedTimeRangeTrackInAsset:(id)a0 assetTrack:(id)a1 error:(out id *)a2;
+ (struct { struct { long long x0; int x1; unsigned int x2; long long x3; } x0; struct { long long x0; int x1; unsigned int x2; long long x3; } x1; })conformRange:(struct { struct { long long x0; int x1; unsigned int x2; long long x3; } x0; struct { long long x0; int x1; unsigned int x2; long long x3; } x1; })a0 inRange:(struct { struct { long long x0; int x1; unsigned int x2; long long x3; } x0; struct { long long x0; int x1; unsigned int x2; long long x3; } x1; })a1;
+ (struct { struct { long long x0; int x1; unsigned int x2; long long x3; } x0; struct { long long x0; int x1; unsigned int x2; long long x3; } x1; })convertTimeRange:(struct { struct { long long x0; int x1; unsigned int x2; long long x3; } x0; struct { long long x0; int x1; unsigned int x2; long long x3; } x1; })a0 toMaximumTimeScaleOfRange:(struct { struct { long long x0; int x1; unsigned int x2; long long x3; } x0; struct { long long x0; int x1; unsigned int x2; long long x3; } x1; })a1;
+ (id)debugDescriptionOfAssetTrack:(id)a0;
+ (id)deepMutableCopyVideoComposition:(id)a0;
+ (id)defaultExportCodecForHDRVideo:(BOOL)a0;
+ (id)defaultOutputColorSpaceForComposition:(id)a0;
+ (id)defaultVideoSettingsForAVAssetReader;
+ (BOOL)deviceSupportsHardware10BitHEVCEncoding;
+ (BOOL)deviceSupportsHardwareHEVCEncoding;
+ (BOOL)deviceSupportsHighDynamicRangeVideo;
+ (struct { long long x0; long long x1; })encodedPixelSizeOfTrack:(id)a0 oriented:(BOOL)a1;
+ (id)firstEnabledVideoTrackInAsset:(id)a0 error:(out id *)a1;
+ (id)getCinematicAudioParametersFromAudioMix:(id)a0;
+ (id)indexesOfSemanticStyleVideoSampleSlices:(id)a0;
+ (BOOL)isAVAssetDolbyProfile5:(id)a0 error:(out id *)a1;
+ (BOOL)isAVAssetHDR:(id)a0 error:(out id *)a1;
+ (BOOL)isAssetUnsupportedCorruptPortraitVideo:(id)a0;
+ (BOOL)isAssetUnsupportedLegacyPortraitVideo:(id)a0;
+ (BOOL)isMetadataTrackStillImageDisplayTimeMarkerInLivePhoto:(id)a0;
+ (BOOL)isMetadataTrackWithLivePhotoInfo:(id)a0;
+ (BOOL)isMetadataTrackWithStillImageDimensionsInLivePhoto:(id)a0;
+ (BOOL)isMetadataTrackWithStillImageTransformInLivePhoto:(id)a0;
+ (BOOL)metadataTrack:(id)a0 containsIdentifier:(id)a1;
+ (BOOL)metadataTrack:(id)a0 containsIdentifiers:(id)a1;
+ (BOOL)metadataTrackContainsCinematicAudioData:(id)a0;
+ (BOOL)metadataTrackContainsLegacyCinematicAudioData:(id)a0;
+ (BOOL)metadataTrackContainsPortraitVideoData:(id)a0;
+ (BOOL)metadataTrackContainsSemanticStyleData:(id)a0;
+ (id)metadataTrackWithCinematicAudioDataInAsset:(id)a0;
+ (id)metadataTrackWithIdenfifier:(id)a0 forAsset:(id)a1;
+ (id)metadataTrackWithLivePhotoInfoInAsset:(id)a0;
+ (id)metadataTrackWithPortraitVideoDataInAsset:(id)a0;
+ (id)metadataTrackWithStillImageDimensionsInLivePhotoAsset:(id)a0;
+ (id)metadataTrackWithStillImageDisplayTimeMarkerInLivePhotoAsset:(id)a0;
+ (id)metadataTrackWithStillImageTransformInLivePhotoAsset:(id)a0;
+ (struct { long long x0; int x1; unsigned int x2; long long x3; })minimumFrameDurationForAsset:(id)a0;
+ (struct { long long x0; int x1; unsigned int x2; long long x3; })minimumFrameDurationForAsset:(id)a0 videoComposition:(id)a1;
+ (struct { long long x0; int x1; unsigned int x2; long long x3; })minimumFrameDurationForAssetTrack:(id)a0;
+ (struct { long long x0; long long x1; })naturalSizeOfTrack:(id)a0 oriented:(BOOL)a1;
+ (id)newPixelBufferOfSize:(struct { long long x0; long long x1; })a0 format:(unsigned int)a1;
+ (unsigned long long)nominalFrameRateRoundedToNearestTraditionalFrameRate:(float)a0;
+ (id)originalCodecOfVideoTrack:(id)a0;
+ (id)pixelFormatStringForCVPixelBuffer:(struct __CVBuffer { } *)a0;
+ (struct CGAffineTransform { double x0; double x1; double x2; double x3; double x4; double x5; })preferredTransformFromOrientation:(long long)a0 size:(struct { long long x0; long long x1; })a1;
+ (BOOL)readFromReader:(id)a0 andWriteToWriter:(id)a1 stillImageTime:(struct { long long x0; int x1; unsigned int x2; long long x3; })a2 createCustomMetadata:(BOOL)a3 geometryTransform:(id)a4 inputSize:(struct CGSize { double x0; double x1; })a5 outputSize:(struct CGSize { double x0; double x1; })a6 progress:(id)a7 error:(out id *)a8;
+ (void)readNextPixelBuffer:(id)a0 output:(id)a1 block:(id /* block */)a2;
+ (void)readNextSampleBuffer:(id)a0 output:(id)a1 block:(id /* block */)a2;
+ (struct { long long x0; int x1; unsigned int x2; long long x3; })readStillImageTimeFromVideoAsset:(id)a0;
+ (id)readTimedMetadataGroupAtTime:(struct { long long x0; int x1; unsigned int x2; long long x3; })a0 fromTrack:(id)a1 outputSettings:(id)a2 videoComposition:(id)a3 error:(out id *)a4;
+ (struct __CVBuffer { } *)readVideoFrameAtTime:(struct { long long x0; int x1; unsigned int x2; long long x3; })a0 fromAsset:(id)a1 outputSettings:(id)a2 videoComposition:(id)a3 auxiliaryImageType:(long long)a4 error:(out id *)a5;
+ (struct __CVBuffer { } *)readVideoFrameAtTime:(struct { long long x0; int x1; unsigned int x2; long long x3; })a0 fromAsset:(id)a1 reader:(id)a2 readerOutput:(id)a3 error:(out id *)a4;
+ (id)readerOutputForAsset:(id)a0 outputSettings:(id)a1 videoComposition:(id)a2 auxiliaryImageType:(long long)a3 error:(out id *)a4;
+ (id)readerOutputForAssetTrack:(id)a0 outputSettings:(id)a1 error:(out id *)a2;
+ (id)realTimeConsumptionAssetReaderForAsset:(id)a0 error:(id *)a1;
+ (id)repeatAudio:(id)a0 count:(long long)a1 error:(out id *)a2;
+ (id)repeatVideo:(id)a0 count:(long long)a1 error:(out id *)a2;
+ (id)repeatVideoComposition:(id)a0 count:(long long)a1 error:(out id *)a2;
+ (id)requiredVideoCompositionOutputTracksForAsset:(id)a0;
+ (id)rgbVideoSettingsForAVAssetReader;
+ (id)semanticStylePropertiesFromMetadataGroup:(id)a0 keyTime:(struct { long long x0; int x1; unsigned int x2; long long x3; })a1 error:(out id *)a2;
+ (BOOL)track:(id)a0 hasSamplesForEachSampleInTrack:(id)a1;
+ (BOOL)trimCompositionTracks:(id)a0 toRange:(struct { struct { long long x0; int x1; unsigned int x2; long long x3; } x0; struct { long long x0; int x1; unsigned int x2; long long x3; } x1; })a1 error:(out id *)a2;
+ (BOOL)updateVideoMetadataAtURL:(id)a0 withItems:(id)a1 stillImageTime:(struct { long long x0; int x1; unsigned int x2; long long x3; })a2 error:(out id *)a3;
+ (id)urlOfAVAsset:(id)a0;
+ (id)validateAsset:(id)a0 error:(out id *)a1;
+ (BOOL)validateMainVideoTrack:(id)a0 potentiallyCorruptedRange:(out struct { struct { long long x0; int x1; unsigned int x2; long long x3; } x0; struct { long long x0; int x1; unsigned int x2; long long x3; } x1; } *)a1 error:(out id *)a2;
+ (id)videoCompositionDescription:(id)a0;
+ (id)videoDescription:(id)a0;
+ (long long)videoOrientationForAsset:(id)a0 videoComposition:(id)a1;
+ (long long)videoOrientationForAssetPreferredTransform:(struct CGAffineTransform { double x0; double x1; double x2; double x3; double x4; double x5; })a0;
+ (BOOL)videoTrackContainsDolbyVisionMetadata:(id)a0;

@end
